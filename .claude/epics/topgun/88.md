---
name: Create operational runbooks for common scenarios
status: open
created: 2025-10-06T15:23:47Z
updated: 2025-10-06T20:39:39Z
github: https://github.com/johnproblems/topgun/issues/195
depends_on: []
parallel: true
conflicts_with: []
---

# Task: Create operational runbooks for common scenarios (scaling, backup, recovery, troubleshooting)

## Description

Create a comprehensive set of operational runbooks that provide step-by-step procedures for managing the Coolify Enterprise platform in production environments. These runbooks serve as the authoritative operational guide for system administrators, DevOps engineers, and on-call staff managing both the platform infrastructure and tenant organizations.

Operational runbooks transform tribal knowledge into documented, repeatable procedures that ensure consistent system management regardless of who is on call. In a multi-tenant enterprise platform like Coolify Enterprise, where hundreds or thousands of organizations depend on reliable service, operational excellence is non-negotiable. Runbooks reduce mean time to resolution (MTTR) during incidents, prevent operational mistakes during routine maintenance, and enable new team members to operate the platform confidently.

**Why This Task is Critical:**

The Coolify Enterprise transformation introduces significant architectural complexity compared to standard Coolify:
1. **Multi-Tenancy**: Organization hierarchy, resource quotas, license enforcement
2. **Infrastructure Automation**: Terraform-managed cloud resources across multiple providers
3. **Real-Time Monitoring**: WebSocket-based dashboards, 30-second metric collection intervals
4. **Background Processing**: Queue workers for deployments, cache warming, resource monitoring
5. **External Dependencies**: Payment gateways, domain registrars, DNS providers, cloud APIs

Without comprehensive runbooks, operators face:
- **Prolonged Incidents**: Teams searching for solutions under pressure leads to extended downtime
- **Inconsistent Operations**: Different operators using different procedures produces variable outcomes
- **Configuration Drift**: Ad-hoc fixes accumulate without documentation, creating unstable state
- **Knowledge Silos**: Critical operational knowledge exists only in the minds of specific individuals
- **Compliance Risks**: Lack of documented procedures fails audit requirements for enterprise customers

**Runbook Coverage:**

This task creates runbooks for the most critical operational scenarios:

1. **Scaling Operations** - Horizontal and vertical scaling of application servers, database clusters, queue workers, and WebSocket servers
2. **Backup and Restore** - Database backups, configuration backups, Terraform state backups, application data backups
3. **Disaster Recovery** - Multi-region failover, data center evacuation, complete system restoration
4. **Performance Troubleshooting** - Slow queries, high CPU/memory, queue congestion, cache issues
5. **Security Incidents** - Compromised credentials, unauthorized access, data leaks, API abuse
6. **Deployment Procedures** - Zero-downtime deployments, rollback procedures, database migration strategies
7. **Monitoring and Alerting** - Alert triage, escalation procedures, metric interpretation
8. **Organization Management** - Tenant onboarding, license management, resource quota adjustments
9. **Infrastructure Provisioning** - Terraform workflow recovery, cloud provider issues, networking problems
10. **Integration Failures** - Payment gateway issues, DNS propagation delays, webhook failures

**Runbook Structure:**

Each runbook follows a consistent template ensuring quick comprehension under pressure:

- **Overview**: What the procedure accomplishes and when to use it
- **Prerequisites**: Required access, tools, information before starting
- **Impact Assessment**: Expected downtime, affected users, rollback options
- **Step-by-Step Procedure**: Numbered steps with exact commands and expected outputs
- **Validation Steps**: How to confirm the procedure succeeded
- **Rollback Procedure**: Steps to undo changes if something goes wrong
- **Related Runbooks**: Cross-references to related procedures
- **Troubleshooting**: Common issues and their resolutions
- **Automation Notes**: Opportunities for future automation

**Integration with Existing Documentation:**

These runbooks complement but do not duplicate existing documentation:
- **Feature Documentation** (Tasks 82-85): User-facing guides for using enterprise features
- **API Documentation** (Task 86): Developer reference for API integration
- **Migration Guide** (Task 87): One-time process for upgrading standard Coolify to enterprise
- **Monitoring Dashboards** (Task 91): Real-time observability and metrics

Runbooks are **operator-focused** and **incident-driven**, designed for use during high-pressure scenarios when systems are broken or require immediate changes. They assume the operator has system access and operational authority but may be unfamiliar with specific procedures.

**Maintenance and Evolution:**

Runbooks are living documents that evolve with the platform:
- **Post-Incident Reviews**: After each incident, update relevant runbooks with lessons learned
- **Quarterly Reviews**: Engineering team reviews runbooks for accuracy and completeness
- **Operator Feedback**: On-call staff submit improvement suggestions
- **Version Control**: All runbooks stored in Git, changes reviewed via pull requests
- **Change Management**: Major runbook changes require approval from operations lead

This task establishes the foundation for operational excellence, transforming Coolify Enterprise from a technically sophisticated platform into a reliably operated production system.

## Acceptance Criteria

- [ ] Scaling runbooks created for all major components (app servers, databases, workers, WebSocket servers)
- [ ] Backup runbooks cover all critical data (PostgreSQL, configuration files, Terraform state, uploaded assets)
- [ ] Disaster recovery runbooks tested via tabletop exercises or actual DR drills
- [ ] Performance troubleshooting runbooks address top 10 most common issues
- [ ] Security incident runbooks follow industry best practices (NIST, SANS)
- [ ] Deployment runbooks align with CI/CD pipeline (Task 89)
- [ ] Monitoring runbooks integrate with alerting configuration (Task 91)
- [ ] Organization management runbooks reflect actual workflows
- [ ] Infrastructure provisioning runbooks cover all supported cloud providers
- [ ] Integration failure runbooks provide recovery steps for external dependencies
- [ ] All runbooks follow consistent template structure
- [ ] Runbooks stored in version-controlled documentation repository
- [ ] Runbooks accessible via searchable wiki or documentation portal
- [ ] Runbook validation checklist created for each procedure
- [ ] Escalation paths clearly defined for scenarios requiring additional expertise
- [ ] Runbook owner assigned for each document (responsible for accuracy)
- [ ] On-call team trained on critical runbooks (scaling, backup, disaster recovery)
- [ ] Runbook effectiveness measured via MTTR improvements
- [ ] Quarterly review process established with documented schedule
- [ ] Feedback mechanism created for operators to suggest improvements

## Technical Details

### File Paths

**Runbook Documentation:**
- `/home/topgun/topgun/docs/operations/runbooks/` (new directory)
- `/home/topgun/topgun/docs/operations/runbooks/01-scaling/` (scaling procedures)
- `/home/topgun/topgun/docs/operations/runbooks/02-backup-restore/` (backup and recovery)
- `/home/topgun/topgun/docs/operations/runbooks/03-disaster-recovery/` (DR procedures)
- `/home/topgun/topgun/docs/operations/runbooks/04-troubleshooting/` (debugging guides)
- `/home/topgun/topgun/docs/operations/runbooks/05-security/` (security incident response)
- `/home/topgun/topgun/docs/operations/runbooks/06-deployment/` (deployment procedures)
- `/home/topgun/topgun/docs/operations/runbooks/07-monitoring/` (alert response)
- `/home/topgun/topgun/docs/operations/runbooks/08-organization-management/` (tenant operations)
- `/home/topgun/topgun/docs/operations/runbooks/09-infrastructure/` (Terraform and cloud)
- `/home/topgun/topgun/docs/operations/runbooks/10-integrations/` (external service issues)
- `/home/topgun/topgun/docs/operations/runbooks/templates/runbook-template.md` (standard template)

**Automation Scripts:**
- `/home/topgun/topgun/scripts/operations/scale-workers.sh` (queue worker scaling)
- `/home/topgun/topgun/scripts/operations/backup-database.sh` (automated backup)
- `/home/topgun/topgun/scripts/operations/restore-database.sh` (automated restore)
- `/home/topgun/topgun/scripts/operations/validate-deployment.sh` (deployment validation)
- `/home/topgun/topgun/scripts/operations/health-check.sh` (system health validation)

**Configuration:**
- `/home/topgun/topgun/config/operations.php` (operational configuration)
- `/home/topgun/topgun/.env.operations` (operational environment variables)

### Runbook Template Structure

**File:** `docs/operations/runbooks/templates/runbook-template.md`

```markdown
# [Runbook Title]

**Last Updated:** [Date]
**Owner:** [Name/Team]
**Severity:** [Low/Medium/High/Critical]
**Estimated Time:** [Duration]

## Overview

### Purpose
[What this runbook accomplishes and when to use it]

### When to Use
- [Scenario 1]
- [Scenario 2]
- [Scenario 3]

### Expected Outcome
[What should be true after completing this runbook]

## Prerequisites

### Required Access
- [ ] SSH access to production servers
- [ ] Database credentials (read-only or read-write)
- [ ] Cloud provider console access
- [ ] Kubernetes/Docker access (if applicable)
- [ ] GitHub repository access
- [ ] Monitoring dashboard access

### Required Tools
- [ ] Tool 1 (version X.X)
- [ ] Tool 2 (version X.X)
- [ ] Tool 3 (version X.X)

### Required Information
- [ ] Information item 1
- [ ] Information item 2
- [ ] Information item 3

## Impact Assessment

### Affected Systems
- [System 1]
- [System 2]
- [System 3]

### Expected Downtime
[None / Partial / Complete - Duration]

### User Impact
[Description of impact on end users]

### Rollback Capability
[Can this be rolled back? If so, reference rollback section]

### Risk Level
[Low / Medium / High / Critical]

## Procedure

### Step 1: [Action Name]

**Description:** [What this step accomplishes]

**Commands:**
```bash
# Exact commands to run
command --with-flags argument
```

**Expected Output:**
```
Expected output here
```

**Validation:**
- [ ] Validation check 1
- [ ] Validation check 2

**Troubleshooting:**
- If [error], then [solution]
- If [problem], then [action]

---

### Step 2: [Action Name]

[Repeat structure for each step]

---

## Validation

### Functional Validation
- [ ] Check 1: [How to verify]
- [ ] Check 2: [How to verify]
- [ ] Check 3: [How to verify]

### Performance Validation
- [ ] Metric 1 is within acceptable range
- [ ] Metric 2 has improved
- [ ] No degradation in metric 3

### Monitoring Validation
- [ ] Alerts cleared in monitoring system
- [ ] Dashboards show healthy state
- [ ] Logs confirm successful operation

## Rollback Procedure

### When to Rollback
[Criteria for determining rollback is necessary]

### Rollback Steps

1. [Rollback step 1]
2. [Rollback step 2]
3. [Rollback step 3]

### Rollback Validation
- [ ] System restored to previous state
- [ ] No data loss confirmed
- [ ] Users unaffected by rollback

## Related Runbooks

- [Related Runbook 1](../link/to/runbook.md)
- [Related Runbook 2](../link/to/runbook.md)
- [Related Runbook 3](../link/to/runbook.md)

## Troubleshooting

### Common Issues

**Issue 1: [Problem Description]**
- **Symptoms:** [What you observe]
- **Cause:** [Root cause]
- **Solution:** [How to fix]
- **Prevention:** [How to avoid in future]

**Issue 2: [Problem Description]**
- **Symptoms:** [What you observe]
- **Cause:** [Root cause]
- **Solution:** [How to fix]
- **Prevention:** [How to avoid in future]

## Escalation

### When to Escalate
- [Condition requiring escalation 1]
- [Condition requiring escalation 2]

### Escalation Contacts
- **Primary:** [Name/Role] - [Contact Method]
- **Secondary:** [Name/Role] - [Contact Method]
- **Emergency:** [Name/Role] - [Contact Method]

## Automation Opportunities

[Ideas for automating this runbook in the future]

## Change Log

| Date | Author | Changes |
|------|--------|---------|
| 2025-01-15 | Jane Doe | Initial creation |
| 2025-02-20 | John Smith | Added rollback procedure |
| 2025-03-10 | Alice Johnson | Updated for new monitoring system |

## Appendix

### Useful Commands Reference

```bash
# Command category 1
command1 --help

# Command category 2
command2 --info
```

### External Documentation Links

- [Vendor Documentation](https://example.com/docs)
- [Internal Wiki Page](https://wiki.internal/page)
- [Monitoring Dashboard](https://monitoring.internal/dashboard)
```

### Example Runbook: Database Backup

**File:** `docs/operations/runbooks/02-backup-restore/database-backup.md`

```markdown
# Database Backup - PostgreSQL Primary Database

**Last Updated:** 2025-10-06
**Owner:** DevOps Team
**Severity:** High
**Estimated Time:** 15-30 minutes

## Overview

### Purpose
Create a full backup of the PostgreSQL primary database containing all organization data, applications, deployments, and configurations. This runbook covers both manual backups (for pre-maintenance) and automated backup verification.

### When to Use
- Before major database migrations
- Before schema changes or Coolify version upgrades
- To create point-in-time backup before risky operations
- To verify automated backup system is functioning
- After detecting database corruption or data issues

### Expected Outcome
- Full database dump stored in encrypted S3-compatible storage
- Backup metadata recorded in operations log
- Backup validation confirms integrity
- Restore test confirms backup is usable

## Prerequisites

### Required Access
- [ ] SSH access to primary database server
- [ ] PostgreSQL superuser credentials
- [ ] S3-compatible object storage credentials (AWS S3, MinIO, DigitalOcean Spaces)
- [ ] Access to monitoring dashboard to pause alerts

### Required Tools
- [ ] `pg_dump` (version 15+)
- [ ] `aws-cli` or `s3cmd` (for S3 uploads)
- [ ] `gpg` (for encryption)
- [ ] `sha256sum` (for integrity verification)

### Required Information
- [ ] Database name: `coolify_enterprise`
- [ ] Database host: `db.coolify.internal` or IP address
- [ ] S3 bucket name: `coolify-backups-production`
- [ ] Backup retention policy: 30 days daily, 12 months monthly

## Impact Assessment

### Affected Systems
- PostgreSQL primary database (read performance may degrade during backup)
- S3 storage bucket (will store 10-50GB backup file)
- Network bandwidth (backup transfer consumes bandwidth)

### Expected Downtime
None - read-only operations continue normally, writes may experience minimal latency (<50ms)

### User Impact
Minimal - users may notice slight slowdown in dashboard load times during backup execution

### Rollback Capability
N/A - this is a read-only operation, no rollback needed

### Risk Level
Low - backup operation does not modify production data

## Procedure

### Step 1: Pause Non-Critical Monitoring Alerts

**Description:** Temporarily silence alerts for database performance metrics that may trigger during backup (high CPU, increased I/O).

**Commands:**
```bash
# Pause alerts via monitoring API (adjust for your monitoring system)
curl -X POST https://monitoring.coolify.internal/api/alerts/pause \
  -H "Authorization: Bearer $MONITORING_TOKEN" \
  -d '{"alert_name": "database-high-cpu", "duration": 1800}'

curl -X POST https://monitoring.coolify.internal/api/alerts/pause \
  -H "Authorization: Bearer $MONITORING_TOKEN" \
  -d '{"alert_name": "database-high-io", "duration": 1800}'
```

**Expected Output:**
```json
{"status": "success", "message": "Alert paused for 1800 seconds"}
```

**Validation:**
- [ ] Alerts show as paused in monitoring dashboard
- [ ] Critical alerts (downtime, data corruption) remain active

**Troubleshooting:**
- If API call fails, manually pause alerts via monitoring UI
- If unable to pause, proceed anyway - alerts will auto-resolve after backup completes

---

### Step 2: Create Backup Directory

**Description:** Create timestamped directory for backup files with metadata.

**Commands:**
```bash
# Create backup directory with timestamp
export BACKUP_TIMESTAMP=$(date +%Y%m%d-%H%M%S)
export BACKUP_DIR="/var/backups/postgresql/$BACKUP_TIMESTAMP"
mkdir -p $BACKUP_DIR

# Log backup start
echo "Backup started at $(date)" | tee $BACKUP_DIR/backup.log
```

**Expected Output:**
```
Backup started at Mon Oct  6 14:30:00 UTC 2025
```

**Validation:**
- [ ] Directory created successfully
- [ ] Timestamp variable set correctly
- [ ] Log file created

---

### Step 3: Execute pg_dump

**Description:** Create full database dump with all schemas, data, and permissions.

**Commands:**
```bash
# Execute pg_dump with compression
pg_dump \
  --host=db.coolify.internal \
  --port=5432 \
  --username=postgres \
  --dbname=coolify_enterprise \
  --format=custom \
  --compress=9 \
  --verbose \
  --file=$BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump \
  2>&1 | tee -a $BACKUP_DIR/backup.log
```

**Expected Output:**
```
pg_dump: last built-in OID is 16383
pg_dump: reading extensions
pg_dump: identifying extension members
pg_dump: reading schemas
pg_dump: reading user-defined tables
...
pg_dump: dumping contents of table public.organizations
pg_dump: dumping contents of table public.applications
...
pg_dump: finished main parallel loop
```

**Validation:**
- [ ] Dump file created with size > 1GB (typical for production)
- [ ] No error messages in output
- [ ] File permissions are 600 (read-write for owner only)

**Troubleshooting:**
- If connection fails, verify database is accessible: `psql -h db.coolify.internal -U postgres -l`
- If "out of memory", reduce `--compress` level to 6
- If slow (>30 minutes), consider using parallel dump: `--jobs=4`

---

### Step 4: Create Metadata File

**Description:** Document backup metadata for future restore operations.

**Commands:**
```bash
# Create metadata file
cat > $BACKUP_DIR/metadata.json <<EOF
{
  "backup_timestamp": "$BACKUP_TIMESTAMP",
  "database_name": "coolify_enterprise",
  "database_version": "$(psql -h db.coolify.internal -U postgres -t -c 'SELECT version();')",
  "backup_size_bytes": $(stat -f%z $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump 2>/dev/null || stat -c%s $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump),
  "backup_method": "pg_dump --format=custom --compress=9",
  "created_by": "$(whoami)",
  "created_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
}
EOF

cat $BACKUP_DIR/metadata.json
```

**Expected Output:**
```json
{
  "backup_timestamp": "20251006-143000",
  "database_name": "coolify_enterprise",
  "database_version": " PostgreSQL 15.4 on x86_64-pc-linux-gnu",
  "backup_size_bytes": 5368709120,
  "backup_method": "pg_dump --format=custom --compress=9",
  "created_by": "postgres",
  "created_at": "2025-10-06T14:30:00Z"
}
```

**Validation:**
- [ ] Metadata file created
- [ ] JSON is valid (test with `jq . $BACKUP_DIR/metadata.json`)
- [ ] File size recorded accurately

---

### Step 5: Encrypt Backup File

**Description:** Encrypt backup using GPG for secure storage.

**Commands:**
```bash
# Encrypt backup file with GPG (using pre-configured key)
gpg --encrypt \
  --recipient backups@coolify.internal \
  --output $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg \
  $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump

# Remove unencrypted dump
rm $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump

# Verify encryption
gpg --list-packets $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg | head -20
```

**Expected Output:**
```
:pubkey enc packet: version 3, algo 1, keyid A1B2C3D4E5F6G7H8
        data: [4096 bits]
:encrypted data packet:
        length: 5368709120
        mdc_method: 2
```

**Validation:**
- [ ] Encrypted file created (.dump.gpg extension)
- [ ] Unencrypted dump removed
- [ ] Encrypted file size approximately equal to original

**Troubleshooting:**
- If GPG key not found, import from keyring: `gpg --import /etc/coolify/backup-key.asc`
- If encryption fails, skip this step and note in metadata that backup is unencrypted

---

### Step 6: Generate Checksum

**Description:** Create SHA256 checksum for integrity validation.

**Commands:**
```bash
# Generate checksum
sha256sum $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg \
  > $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg.sha256

# Display checksum
cat $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg.sha256
```

**Expected Output:**
```
a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0u1v2w3x4y5z6  /var/backups/postgresql/20251006-143000/coolify_enterprise_20251006-143000.dump.gpg
```

**Validation:**
- [ ] Checksum file created
- [ ] Checksum is 64 characters (SHA256)

---

### Step 7: Upload to S3 Storage

**Description:** Upload encrypted backup to S3-compatible object storage.

**Commands:**
```bash
# Upload backup file
aws s3 cp \
  $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg \
  s3://coolify-backups-production/postgresql/daily/$BACKUP_TIMESTAMP/ \
  --storage-class INTELLIGENT_TIERING \
  --metadata backup-type=postgresql,environment=production,retention-days=30

# Upload metadata
aws s3 cp \
  $BACKUP_DIR/metadata.json \
  s3://coolify-backups-production/postgresql/daily/$BACKUP_TIMESTAMP/

# Upload checksum
aws s3 cp \
  $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg.sha256 \
  s3://coolify-backups-production/postgresql/daily/$BACKUP_TIMESTAMP/
```

**Expected Output:**
```
upload: ./coolify_enterprise_20251006-143000.dump.gpg to s3://coolify-backups-production/postgresql/daily/20251006-143000/coolify_enterprise_20251006-143000.dump.gpg
upload: ./metadata.json to s3://coolify-backups-production/postgresql/daily/20251006-143000/metadata.json
upload: ./coolify_enterprise_20251006-143000.dump.gpg.sha256 to s3://coolify-backups-production/postgresql/daily/20251006-143000/coolify_enterprise_20251006-143000.dump.gpg.sha256
```

**Validation:**
- [ ] All three files uploaded successfully
- [ ] S3 storage class set to INTELLIGENT_TIERING
- [ ] Metadata tags applied

**Troubleshooting:**
- If upload fails, check AWS credentials: `aws sts get-caller-identity`
- If slow, increase multipart upload threshold: `aws configure set default.s3.multipart_threshold 64MB`
- If network timeout, retry with exponential backoff

---

### Step 8: Verify Backup Integrity

**Description:** Download and verify backup can be restored.

**Commands:**
```bash
# Download backup from S3
aws s3 cp \
  s3://coolify-backups-production/postgresql/daily/$BACKUP_TIMESTAMP/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg \
  /tmp/verify_$BACKUP_TIMESTAMP.dump.gpg

# Verify checksum
sha256sum -c <(echo "$(cat $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg.sha256)")

# Test restore to temporary database (optional but recommended)
createdb -h db.coolify.internal -U postgres coolify_test_restore_$BACKUP_TIMESTAMP

gpg --decrypt /tmp/verify_$BACKUP_TIMESTAMP.dump.gpg | \
  pg_restore \
    --host=db.coolify.internal \
    --username=postgres \
    --dbname=coolify_test_restore_$BACKUP_TIMESTAMP \
    --verbose

# Verify restore
psql -h db.coolify.internal -U postgres -d coolify_test_restore_$BACKUP_TIMESTAMP \
  -c "SELECT COUNT(*) FROM organizations;"

# Drop test database
dropdb -h db.coolify.internal -U postgres coolify_test_restore_$BACKUP_TIMESTAMP

# Clean up
rm /tmp/verify_$BACKUP_TIMESTAMP.dump.gpg
```

**Expected Output:**
```
/var/backups/postgresql/20251006-143000/coolify_enterprise_20251006-143000.dump.gpg: OK
CREATE DATABASE
pg_restore: restoring data for table "public.organizations"
...
 count
-------
   542
(1 row)

DROP DATABASE
```

**Validation:**
- [ ] Checksum verification passes
- [ ] Test restore completes without errors
- [ ] Organization count matches production
- [ ] Test database dropped successfully

**Troubleshooting:**
- If checksum fails, backup is corrupted - re-run entire procedure
- If restore fails, check PostgreSQL logs: `tail -f /var/log/postgresql/postgresql-15-main.log`
- If test database not dropped, manually drop: `dropdb -h db.coolify.internal -U postgres coolify_test_restore_$BACKUP_TIMESTAMP --force`

---

### Step 9: Clean Up Local Backup Files

**Description:** Remove local backup files after successful upload and verification.

**Commands:**
```bash
# Remove local backup directory
rm -rf $BACKUP_DIR

# Verify cleanup
ls -la /var/backups/postgresql/ | grep $BACKUP_TIMESTAMP
```

**Expected Output:**
```
(no output - directory removed)
```

**Validation:**
- [ ] Local backup files deleted
- [ ] S3 backup still accessible

---

### Step 10: Resume Monitoring Alerts

**Description:** Re-enable monitoring alerts paused in Step 1.

**Commands:**
```bash
# Resume alerts
curl -X POST https://monitoring.coolify.internal/api/alerts/resume \
  -H "Authorization: Bearer $MONITORING_TOKEN" \
  -d '{"alert_name": "database-high-cpu"}'

curl -X POST https://monitoring.coolify.internal/api/alerts/resume \
  -H "Authorization: Bearer $MONITORING_TOKEN" \
  -d '{"alert_name": "database-high-io"}'
```

**Expected Output:**
```json
{"status": "success", "message": "Alert resumed"}
```

**Validation:**
- [ ] Alerts show as active in monitoring dashboard

---

### Step 11: Log Backup Completion

**Description:** Record backup completion in operations log.

**Commands:**
```bash
# Log to operations database
psql -h db.coolify.internal -U postgres -d coolify_enterprise -c \
  "INSERT INTO operation_logs (operation_type, status, details, created_at) VALUES \
  ('database_backup', 'success', '{\"timestamp\": \"$BACKUP_TIMESTAMP\", \"size_gb\": $(bc <<< \"scale=2; $(stat -c%s $BACKUP_DIR/coolify_enterprise_$BACKUP_TIMESTAMP.dump.gpg) / 1073741824\")}', NOW());"

# Log to file
echo "Backup completed successfully at $(date)" | tee -a /var/log/coolify/backups.log

# Send notification (optional)
curl -X POST https://slack.coolify.internal/webhook \
  -d '{"text": "✅ PostgreSQL backup completed: '$BACKUP_TIMESTAMP'"}'
```

**Expected Output:**
```
INSERT 0 1
Backup completed successfully at Mon Oct  6 15:00:00 UTC 2025
ok
```

**Validation:**
- [ ] Operation logged in database
- [ ] Log file updated
- [ ] Notification sent (if configured)

---

## Validation

### Functional Validation
- [ ] Backup file exists in S3: `aws s3 ls s3://coolify-backups-production/postgresql/daily/$BACKUP_TIMESTAMP/`
- [ ] Backup file size > 1GB (verify: `aws s3 ls s3://coolify-backups-production/postgresql/daily/$BACKUP_TIMESTAMP/ --human-readable`)
- [ ] Metadata file exists and is valid JSON
- [ ] Checksum verification passes
- [ ] Test restore completed successfully

### Performance Validation
- [ ] Backup completed in < 30 minutes
- [ ] Database performance metrics returned to normal
- [ ] No user-reported issues during backup window

### Monitoring Validation
- [ ] Alerts resumed and functioning
- [ ] No critical alerts triggered during backup
- [ ] Backup completion logged in monitoring system

## Rollback Procedure

Not applicable - this is a read-only backup operation with no changes to production systems.

## Related Runbooks

- [Database Restore](./database-restore.md) - Restore from backup
- [Database Migration](../06-deployment/database-migration.md) - Pre-migration backup
- [Disaster Recovery](../03-disaster-recovery/database-failover.md) - Complete database recovery

## Troubleshooting

### Common Issues

**Issue 1: pg_dump Connection Timeout**
- **Symptoms:** `pg_dump: error: connection to server at "db.coolify.internal" (10.0.1.5), port 5432 failed: timeout`
- **Cause:** Network issue, firewall rule, or database overload
- **Solution:**
  1. Verify database is accessible: `pg_isready -h db.coolify.internal -U postgres`
  2. Check firewall rules allow connection from backup server
  3. Increase timeout: `export PGCONNECT_TIMEOUT=60`
  4. Retry backup
- **Prevention:** Monitor database connection pool metrics, set up connection health checks

**Issue 2: Out of Disk Space During Backup**
- **Symptoms:** `pg_dump: error: could not write to file: No space left on device`
- **Cause:** Backup volume full
- **Solution:**
  1. Check disk space: `df -h /var/backups`
  2. Remove old local backups: `find /var/backups/postgresql -mtime +7 -delete`
  3. Or write directly to S3: `pg_dump | gzip | aws s3 cp - s3://bucket/backup.sql.gz`
- **Prevention:** Monitor backup volume disk space, set up alerts at 80% threshold

**Issue 3: S3 Upload Fails with "Access Denied"**
- **Symptoms:** `upload failed: s3://coolify-backups-production/... Access Denied`
- **Cause:** AWS credentials expired or insufficient permissions
- **Solution:**
  1. Verify credentials: `aws sts get-caller-identity`
  2. Check IAM permissions include `s3:PutObject` on backup bucket
  3. Refresh credentials if using temporary tokens
  4. Retry upload
- **Prevention:** Use IAM roles instead of access keys, monitor credential expiration

**Issue 4: Backup Integrity Verification Fails**
- **Symptoms:** `sha256sum: WARNING: 1 computed checksum did NOT match`
- **Cause:** File corruption during transfer
- **Solution:**
  1. Re-download backup from S3
  2. Re-verify checksum
  3. If still fails, backup is corrupted - re-run entire backup procedure
  4. Investigate network or storage issues causing corruption
- **Prevention:** Use S3 versioning, enable S3 object checksums

**Issue 5: Test Restore Takes Too Long**
- **Symptoms:** Restore running for > 60 minutes
- **Cause:** Large database, slow disk I/O, or resource contention
- **Solution:**
  1. Skip test restore for routine backups (test monthly instead of daily)
  2. Use faster test server with SSD storage
  3. Restore to smaller test database (sample of data)
- **Prevention:** Schedule test restores during off-peak hours

## Escalation

### When to Escalate
- Backup fails 3 consecutive times
- Backup corruption detected during verification
- S3 storage quota exceeded
- Database performance degraded after backup (not recovered after 1 hour)

### Escalation Contacts
- **Primary:** DevOps Team Lead - Slack @devops-lead, PagerDuty
- **Secondary:** Database Administrator - Slack @dba, Phone +1-555-0100
- **Emergency:** CTO - Phone +1-555-0200 (critical data loss risk only)

## Automation Opportunities

1. **Fully Automated Backups**: Convert this runbook into a scheduled cron job or systemd timer
2. **Monitoring Integration**: Automatically pause/resume alerts during backup without manual API calls
3. **Retention Management**: Automated cleanup of backups older than retention policy (30 days daily, 12 months monthly)
4. **Backup Validation**: Scheduled monthly test restores to verify backup integrity
5. **Alerting**: Automatic notifications to on-call if backup fails or takes too long
6. **Disaster Recovery Testing**: Quarterly automated DR drills using backups

## Change Log

| Date | Author | Changes |
|------|--------|---------|
| 2025-10-06 | DevOps Team | Initial creation for Coolify Enterprise |

## Appendix

### Useful Commands Reference

```bash
# Check database size
psql -h db.coolify.internal -U postgres -c "SELECT pg_size_pretty(pg_database_size('coolify_enterprise'));"

# List all databases
psql -h db.coolify.internal -U postgres -l

# Check backup storage usage
aws s3 ls s3://coolify-backups-production/postgresql/daily/ --recursive --human-readable --summarize

# Decrypt backup file
gpg --decrypt coolify_enterprise_20251006-143000.dump.gpg > coolify_enterprise.dump

# List S3 backups by date
aws s3 ls s3://coolify-backups-production/postgresql/daily/ | sort -r | head -10
```

### External Documentation Links

- [PostgreSQL Backup Documentation](https://www.postgresql.org/docs/current/backup.html)
- [AWS S3 CLI Documentation](https://docs.aws.amazon.com/cli/latest/reference/s3/)
- [GPG Encryption Guide](https://www.gnupg.org/gph/en/manual.html)
- [Coolify Enterprise Operations Wiki](https://wiki.coolify.internal/operations)
```

### Example Runbook: Horizontal Scaling - Queue Workers

**File:** `docs/operations/runbooks/01-scaling/scale-queue-workers.md`

```markdown
# Horizontal Scaling - Queue Workers

**Last Updated:** 2025-10-06
**Owner:** DevOps Team
**Severity:** Medium
**Estimated Time:** 10-15 minutes

## Overview

### Purpose
Scale the number of Laravel Horizon queue workers to handle increased background job volume. This runbook covers both scaling up (adding workers) and scaling down (removing workers) for the following queues:
- `default` - General application jobs
- `deployments` - Application deployment jobs
- `terraform` - Infrastructure provisioning jobs
- `cache-warming` - Branding cache warming jobs
- `monitoring` - Resource monitoring jobs

### When to Use
**Scale Up When:**
- Queue wait time exceeds 5 minutes (check Horizon dashboard)
- Job throughput < 100 jobs/minute during peak hours
- Horizon shows "Jobs Queued" consistently > 1000
- Deployment times increase beyond acceptable SLA
- Monitoring alerts for queue congestion

**Scale Down When:**
- Queue wait time consistently < 30 seconds during off-peak
- Server CPU/memory underutilized (< 40% utilization)
- Cost optimization initiative
- Reduced traffic period (e.g., weekends, holidays)

### Expected Outcome
- Queue wait times reduced to < 2 minutes
- Job throughput increased proportionally to worker count
- No job failures or timeouts
- Graceful worker shutdown (existing jobs complete)

## Prerequisites

### Required Access
- [ ] SSH access to queue worker servers
- [ ] Laravel Horizon dashboard access (https://coolify.internal/horizon)
- [ ] Kubernetes cluster access (if using k8s) OR Docker Swarm manager access
- [ ] Monitoring dashboard access

### Required Tools
- [ ] `kubectl` (if using Kubernetes)
- [ ] `docker` (if using Docker Swarm/Compose)
- [ ] `systemd` (if using systemd services)
- [ ] `horizon` artisan commands

### Required Information
- [ ] Current worker count per queue
- [ ] Target worker count per queue
- [ ] Server capacity (CPU/memory available for additional workers)
- [ ] Queue statistics (from Horizon dashboard)

## Impact Assessment

### Affected Systems
- Queue worker servers (increased CPU/memory usage)
- PostgreSQL database (increased connection count)
- Redis (increased memory usage for queue management)

### Expected Downtime
None - new workers start while existing workers continue processing

### User Impact
Positive - faster deployment times, reduced wait for background jobs

### Rollback Capability
Yes - can scale down workers immediately (see Rollback section)

### Risk Level
Low - adding workers does not affect existing job processing

## Procedure

### Step 1: Assess Current Queue State

**Description:** Review Horizon dashboard to determine optimal worker count.

**Commands:**
```bash
# Access Horizon metrics via artisan
php artisan horizon:status

# Or fetch queue statistics
redis-cli -h redis.coolify.internal LLEN "queues:default"
redis-cli -h redis.coolify.internal LLEN "queues:deployments"
redis-cli -h redis.coolify.internal LLEN "queues:terraform"
```

**Expected Output:**
```
Horizon is running.

Processes: 12
Jobs Processed: 45,832
Jobs Pending: 1,245
Failed Jobs: 3
```

```
"queues:default" 342
"queues:deployments" 567
"queues:terraform" 89
```

**Validation:**
- [ ] Horizon dashboard accessible
- [ ] Queue lengths retrieved
- [ ] Identify queues needing additional capacity

**Troubleshooting:**
- If Horizon shows "Inactive", restart: `php artisan horizon:terminate` then supervisor restarts it
- If Redis connection fails, check: `redis-cli -h redis.coolify.internal PING`

---

### Step 2: Calculate Target Worker Count

**Description:** Determine how many workers to add based on queue length and desired throughput.

**Formula:**
```
Target Workers = (Queue Length / Desired Wait Minutes) / Jobs Per Worker Per Minute
```

**Example Calculation:**
```
deployments queue: 567 jobs
Desired wait: 2 minutes
Worker throughput: 5 jobs/minute (deployment jobs are slow)

Target Workers = (567 / 2) / 5 = 57 workers

Current Workers: 12
Workers to Add: 57 - 12 = 45 workers
```

**Commands:**
```bash
# No commands - manual calculation based on Horizon metrics
echo "Current deployments workers: 12"
echo "Queue length: 567"
echo "Target workers: 57"
echo "Workers to add: 45"
```

**Validation:**
- [ ] Target worker count calculated
- [ ] Server capacity confirmed to support additional workers
- [ ] Memory/CPU headroom available (check: `free -h && mpstat`)

---

### Step 3: Update Horizon Configuration (if needed)

**Description:** Modify `config/horizon.php` if scaling beyond configured maximums.

**Commands:**
```bash
# Edit Horizon configuration
nano config/horizon.php

# Example change:
# 'deployments' => [
#     'connection' => 'redis',
#     'queue' => ['deployments'],
#     'balance' => 'auto',
#     'maxProcesses' => 20,  // CHANGE: Increase from 20 to 60
#     'balanceMaxShift' => 1,
#     'balanceCooldown' => 3,
# ],

# After editing, deploy configuration change
php artisan config:cache
```

**Expected Output:**
```
Configuration cached successfully!
```

**Validation:**
- [ ] Configuration updated
- [ ] Configuration cache cleared and rebuilt
- [ ] No syntax errors in config file

**Troubleshooting:**
- If syntax error, check with: `php artisan config:show horizon`
- Revert changes if errors occur

**Note:** Skip this step if scaling within existing `maxProcesses` limits.

---

### Step 4: Scale Workers (Docker Swarm Example)

**Description:** Increase worker replicas using Docker Swarm.

**Commands:**
```bash
# Scale deployments queue workers
docker service scale coolify_horizon_deployments=57

# Verify scaling operation
docker service ls | grep horizon

# Monitor scaling progress
watch -n 2 "docker service ps coolify_horizon_deployments | grep Running | wc -l"
```

**Expected Output:**
```
coolify_horizon_deployments scaled to 57
overall progress: 57 out of 57 tasks
verify: Service converged

ID                  NAME                                   IMAGE                   NODE                DESIRED STATE       CURRENT STATE
abc123              coolify_horizon_deployments.1          coolify:latest          worker-01           Running             Running 2 minutes ago
def456              coolify_horizon_deployments.2          coolify:latest          worker-02           Running             Running 2 minutes ago
...
```

**Validation:**
- [ ] Service scaled to target count
- [ ] All replicas in "Running" state
- [ ] No "Failed" replicas

**Troubleshooting:**
- If scaling fails, check node capacity: `docker node ls` and `docker node inspect <node-id>`
- If nodes full, add nodes or scale other services down
- If workers crash on startup, check logs: `docker service logs coolify_horizon_deployments --tail 100`

---

### Step 4 Alternative: Scale Workers (Kubernetes Example)

**Description:** Increase worker replicas using Kubernetes.

**Commands:**
```bash
# Scale deployments queue workers
kubectl scale deployment coolify-horizon-deployments --replicas=57 -n coolify

# Verify scaling
kubectl get deployment coolify-horizon-deployments -n coolify

# Monitor pod creation
watch -n 2 "kubectl get pods -n coolify | grep horizon-deployments | grep Running | wc -l"
```

**Expected Output:**
```
deployment.apps/coolify-horizon-deployments scaled

NAME                          READY   UP-TO-DATE   AVAILABLE   AGE
coolify-horizon-deployments   57/57   57           57          5m

57
```

**Validation:**
- [ ] Deployment scaled to target replicas
- [ ] All pods in "Running" state
- [ ] No "CrashLoopBackOff" or "Error" pods

---

### Step 5: Verify Workers Processing Jobs

**Description:** Confirm new workers are consuming jobs from queue.

**Commands:**
```bash
# Check Horizon status
php artisan horizon:status

# Monitor queue length decrease
watch -n 5 "redis-cli -h redis.coolify.internal LLEN queues:deployments"

# Check recent job completions in Horizon
curl -s https://coolify.internal/horizon/api/stats/recent-jobs | jq .
```

**Expected Output:**
```
Horizon is running.
Processes: 57 (was 12)
Jobs Processed: 46,500 (increasing)
Jobs Pending: 423 (decreasing from 567)

"queues:deployments" 423
"queues:deployments" 315 (5 seconds later)
"queues:deployments" 198 (10 seconds later)
```

**Validation:**
- [ ] Process count matches target worker count
- [ ] Queue length decreasing
- [ ] Jobs being processed (check Horizon "Recent Jobs")
- [ ] No error spikes in monitoring

**Troubleshooting:**
- If queue not decreasing, check worker logs for errors
- If workers idle, verify queue name configuration matches
- If database connection errors, increase connection pool size

---

### Step 6: Monitor Resource Usage

**Description:** Ensure scaled workers don't overload infrastructure.

**Commands:**
```bash
# Check server CPU/memory usage
ssh worker-01.coolify.internal "top -b -n 1 | head -20"

# Check database connection count
psql -h db.coolify.internal -U postgres -c \
  "SELECT count(*) as active_connections FROM pg_stat_activity WHERE state = 'active';"

# Check Redis memory usage
redis-cli -h redis.coolify.internal INFO memory | grep used_memory_human
```

**Expected Output:**
```
%Cpu(s):  68.5 us,  12.3 sy  (acceptable - was 45% before scaling)
MiB Mem :  32048.0 total, 8523.5 free  (acceptable - still have headroom)

 active_connections
--------------------
                142  (acceptable - within connection pool limit of 200)

used_memory_human:2.45G  (acceptable - within Redis max memory of 8GB)
```

**Validation:**
- [ ] CPU usage < 85%
- [ ] Memory usage < 85%
- [ ] Database connections < pool limit
- [ ] Redis memory < max memory

**Troubleshooting:**
- If CPU > 90%, consider adding more worker nodes
- If memory > 90%, reduce worker count or increase server memory
- If database connections maxed, increase `max_connections` in PostgreSQL config
- If Redis memory high, increase Redis max memory or add Redis replicas

---

### Step 7: Update Monitoring Dashboards

**Description:** Update capacity planning dashboards with new baseline.

**Commands:**
```bash
# Update Grafana annotation (if using Grafana)
curl -X POST https://grafana.coolify.internal/api/annotations \
  -H "Authorization: Bearer $GRAFANA_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "dashboardId": 12,
    "time": '$(date +%s)'000,
    "tags": ["scaling", "workers"],
    "text": "Scaled deployment workers from 12 to 57"
  }'

# Log scaling event
psql -h db.coolify.internal -U postgres -d coolify_enterprise -c \
  "INSERT INTO operation_logs (operation_type, status, details, created_at) VALUES \
  ('scale_workers', 'success', '{\"queue\": \"deployments\", \"old_count\": 12, \"new_count\": 57}', NOW());"
```

**Expected Output:**
```
{"id":1523,"message":"Annotation added"}

INSERT 0 1
```

**Validation:**
- [ ] Annotation visible in Grafana timeline
- [ ] Operation logged in database

---

## Validation

### Functional Validation
- [ ] Worker count increased to target: `docker service ls` or `kubectl get deploy`
- [ ] All workers in healthy state (no crashes)
- [ ] Queue length decreasing steadily
- [ ] Jobs completing successfully (check Horizon "Completed Jobs")
- [ ] No increase in failed jobs

### Performance Validation
- [ ] Queue wait time reduced to < 2 minutes
- [ ] Job throughput increased proportionally (measure jobs/minute in Horizon)
- [ ] Deployment times back to normal SLA
- [ ] No user-reported slowness or timeouts

### Monitoring Validation
- [ ] CPU usage acceptable (< 85%)
- [ ] Memory usage acceptable (< 85%)
- [ ] Database connection pool healthy
- [ ] Redis memory usage stable
- [ ] No new alerts triggered

## Rollback Procedure

### When to Rollback
- Server resources maxed out (CPU > 95%, memory > 95%)
- Database connection pool exhausted
- Workers crashing repeatedly
- Increased job failure rate after scaling

### Rollback Steps

**Docker Swarm:**
```bash
# Scale back to original count
docker service scale coolify_horizon_deployments=12

# Verify rollback
docker service ls | grep horizon
```

**Kubernetes:**
```bash
# Scale back to original count
kubectl scale deployment coolify-horizon-deployments --replicas=12 -n coolify

# Verify rollback
kubectl get deployment coolify-horizon-deployments -n coolify
```

**Revert Configuration (if changed):**
```bash
# Restore previous config/horizon.php from version control
git checkout config/horizon.php

# Clear config cache
php artisan config:cache

# Restart Horizon
php artisan horizon:terminate
```

### Rollback Validation
- [ ] Worker count returned to original
- [ ] Server resources recovered
- [ ] No lingering crashed workers

## Related Runbooks

- [Vertical Scaling - Add Worker Nodes](./add-worker-nodes.md)
- [Horizon Troubleshooting](../04-troubleshooting/horizon-issues.md)
- [Redis Scaling](./scale-redis.md)
- [Database Connection Pool Tuning](../04-troubleshooting/database-performance.md)

## Troubleshooting

### Common Issues

**Issue 1: Workers Start But Immediately Crash**
- **Symptoms:** `docker service ps` shows replicas in "Failed" state, restarting repeatedly
- **Cause:** Configuration error, missing environment variables, database unreachable
- **Solution:**
  1. Check worker logs: `docker service logs coolify_horizon_deployments --tail 100`
  2. Common errors:
     - "Database connection failed" → verify `DB_HOST` and credentials
     - "Redis connection refused" → verify `REDIS_HOST` accessible from worker nodes
     - "Out of memory" → reduce worker count or increase node memory
  3. Fix configuration error
  4. Retry scaling
- **Prevention:** Test configuration on single worker before mass scaling

**Issue 2: Queue Not Decreasing Despite More Workers**
- **Symptoms:** Worker count increased but queue length stays constant or increases
- **Cause:** Jobs failing and being retried, infinite job loop, workers not consuming correct queue
- **Solution:**
  1. Check failed jobs in Horizon: navigate to "Failed Jobs" tab
  2. Inspect error messages for common failure cause
  3. If jobs failing due to bug, fix code and redeploy
  4. If jobs in infinite loop, manually delete from queue: `redis-cli DEL queues:deployments`
  5. Verify workers configured for correct queue name
- **Prevention:** Monitor failed job rate, set up alerts for failed job threshold

**Issue 3: Database Connection Pool Exhausted**
- **Symptoms:** Workers showing "SQLSTATE[08006] FATAL: remaining connection slots are reserved"
- **Cause:** Too many workers exceeding PostgreSQL `max_connections`
- **Solution:**
  1. Calculate connections needed: workers × max DB connections per worker (typically 2-3)
  2. If workers × 3 > `max_connections`, either:
     - Reduce worker count
     - Increase PostgreSQL `max_connections` (edit `postgresql.conf`, restart PostgreSQL)
     - Implement PgBouncer connection pooler
  3. Restart workers after config change
- **Prevention:** Calculate connection requirements before scaling, use connection pooler

**Issue 4: Uneven Worker Distribution Across Nodes**
- **Symptoms:** Some worker nodes at 100% CPU while others idle
- **Cause:** Docker Swarm/Kubernetes scheduler not balancing evenly
- **Solution:**
  1. Docker Swarm: Add placement constraints or use `--replicas-max-per-node` flag
  2. Kubernetes: Use pod anti-affinity rules or topology spread constraints
  3. Manually redistribute: drain overloaded node, workers reschedule to others
- **Prevention:** Configure scheduler affinity rules, monitor node resource distribution

**Issue 5: Slow Job Processing Despite More Workers**
- **Symptoms:** Worker count increased but job completion rate unchanged
- **Cause:** Bottleneck elsewhere (database, external API, file I/O)
- **Solution:**
  1. Profile slow jobs: add timing metrics to job code
  2. Identify bottleneck (common: database queries, HTTP requests)
  3. Optimize bottleneck:
     - Database: add indexes, optimize queries, scale database
     - External API: implement rate limiting, caching, parallel requests
     - File I/O: use faster storage, implement S3 instead of local disk
  4. Consider job queue prioritization
- **Prevention:** Performance test jobs before deploying, monitor job duration metrics

## Escalation

### When to Escalate
- Worker scaling fails repeatedly (> 3 attempts)
- Server capacity insufficient (need additional infrastructure)
- Database performance degraded after scaling (queries > 5s)
- Application-wide performance issues detected

### Escalation Contacts
- **Primary:** DevOps Team Lead - Slack @devops-lead, PagerDuty
- **Secondary:** Infrastructure Engineer - Slack @infra, Phone +1-555-0150
- **Emergency:** CTO - Phone +1-555-0200 (only for critical business impact)

## Automation Opportunities

1. **Auto-Scaling**: Implement Kubernetes HPA (Horizontal Pod Autoscaler) based on queue length metric
2. **Capacity Planning**: Automated recommendations for worker scaling based on historical queue patterns
3. **Health Checks**: Automatic worker restarts if job failure rate exceeds threshold
4. **Cost Optimization**: Scale down workers automatically during off-peak hours (nights, weekends)
5. **Predictive Scaling**: Machine learning to predict job spikes and pre-scale workers

**Example Auto-Scaling Configuration (Kubernetes HPA):**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: coolify-horizon-deployments
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: coolify-horizon-deployments
  minReplicas: 12
  maxReplicas: 100
  metrics:
  - type: External
    external:
      metric:
        name: redis_queue_length
        selector:
          matchLabels:
            queue: deployments
      target:
        type: Value
        value: "500"  # Scale when queue > 500 jobs
```

## Change Log

| Date | Author | Changes |
|------|--------|---------|
| 2025-10-06 | DevOps Team | Initial creation for Coolify Enterprise |

## Appendix

### Useful Commands Reference

```bash
# Horizon commands
php artisan horizon:status          # Check if Horizon is running
php artisan horizon:pause           # Pause job processing
php artisan horizon:continue        # Resume job processing
php artisan horizon:terminate       # Gracefully terminate Horizon
php artisan horizon:purge deployment # Purge specific queue

# Queue inspection
redis-cli KEYS "queues:*"                    # List all queues
redis-cli LLEN "queues:deployments"          # Queue length
redis-cli LRANGE "queues:deployments" 0 10   # Peek at first 10 jobs

# Worker management (Docker Swarm)
docker service ls                            # List all services
docker service ps coolify_horizon_deployments --no-trunc  # Detailed task list
docker service logs coolify_horizon_deployments --tail 100 --follow  # Stream logs

# Worker management (Kubernetes)
kubectl get pods -n coolify                  # List all pods
kubectl describe pod <pod-name> -n coolify   # Pod details
kubectl logs <pod-name> -n coolify --tail 100 --follow  # Stream logs

# Resource monitoring
top -b -n 1 | grep horizon                   # CPU/memory per worker
docker stats                                 # Container resource usage
kubectl top nodes                            # Kubernetes node usage
```

### External Documentation Links

- [Laravel Horizon Documentation](https://laravel.com/docs/11.x/horizon)
- [Docker Service Scaling](https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/)
- [Kubernetes HPA Documentation](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
- [Redis Queue Management](https://redis.io/docs/data-types/lists/)
```

### Runbook Index and Organization

**File:** `docs/operations/runbooks/README.md`

```markdown
# Coolify Enterprise Operational Runbooks

## Quick Access

**Critical Operations:**
- [Database Backup](./02-backup-restore/database-backup.md) - Create full PostgreSQL backup
- [Database Restore](./02-backup-restore/database-restore.md) - Restore from backup
- [Disaster Recovery - Complete System](./03-disaster-recovery/complete-system-restore.md)
- [Security Incident Response](./05-security/incident-response.md)

**Common Operations:**
- [Scale Queue Workers](./01-scaling/scale-queue-workers.md) - Horizontal scaling for background jobs
- [Scale Application Servers](./01-scaling/scale-app-servers.md) - Horizontal scaling for web traffic
- [Deploy New Version](./06-deployment/zero-downtime-deploy.md) - Zero-downtime deployment
- [Rollback Deployment](./06-deployment/rollback.md) - Undo problematic deployment

## Runbook Categories

### 01 - Scaling Operations
- [Scale Queue Workers](./01-scaling/scale-queue-workers.md)
- [Scale Application Servers](./01-scaling/scale-app-servers.md)
- [Scale Database - Read Replicas](./01-scaling/scale-database-read-replicas.md)
- [Scale Redis Cluster](./01-scaling/scale-redis.md)
- [Scale WebSocket Servers](./01-scaling/scale-websockets.md)
- [Add Worker Nodes (Kubernetes)](./01-scaling/add-worker-nodes-k8s.md)
- [Add Worker Nodes (Docker Swarm)](./01-scaling/add-worker-nodes-swarm.md)

### 02 - Backup & Restore
- [Database Backup](./02-backup-restore/database-backup.md)
- [Database Restore](./02-backup-restore/database-restore.md)
- [Configuration Backup](./02-backup-restore/configuration-backup.md)
- [Terraform State Backup](./02-backup-restore/terraform-state-backup.md)
- [Application Data Backup](./02-backup-restore/application-data-backup.md)
- [Verify Backup Integrity](./02-backup-restore/verify-backup.md)

### 03 - Disaster Recovery
- [Complete System Restore](./03-disaster-recovery/complete-system-restore.md)
- [Database Failover](./03-disaster-recovery/database-failover.md)
- [Multi-Region Failover](./03-disaster-recovery/multi-region-failover.md)
- [Data Center Evacuation](./03-disaster-recovery/datacenter-evacuation.md)

### 04 - Troubleshooting
- [Slow Database Queries](./04-troubleshooting/slow-database-queries.md)
- [High CPU Usage](./04-troubleshooting/high-cpu.md)
- [High Memory Usage](./04-troubleshooting/high-memory.md)
- [Queue Congestion](./04-troubleshooting/queue-congestion.md)
- [Cache Issues](./04-troubleshooting/cache-issues.md)
- [Horizon Worker Issues](./04-troubleshooting/horizon-issues.md)
- [WebSocket Connection Problems](./04-troubleshooting/websocket-issues.md)
- [Application Error Spike](./04-troubleshooting/error-spike.md)

### 05 - Security
- [Security Incident Response](./05-security/incident-response.md)
- [Compromised Credentials Rotation](./05-security/credential-rotation.md)
- [Unauthorized Access Investigation](./05-security/unauthorized-access.md)
- [Data Leak Response](./05-security/data-leak.md)
- [API Abuse Mitigation](./05-security/api-abuse.md)
- [DDoS Attack Response](./05-security/ddos-response.md)

### 06 - Deployment
- [Zero-Downtime Deployment](./06-deployment/zero-downtime-deploy.md)
- [Rollback Deployment](./06-deployment/rollback.md)
- [Database Migration](./06-deployment/database-migration.md)
- [Feature Flag Activation](./06-deployment/feature-flags.md)
- [Blue-Green Deployment](./06-deployment/blue-green.md)
- [Canary Deployment](./06-deployment/canary.md)

### 07 - Monitoring & Alerting
- [Alert Triage](./07-monitoring/alert-triage.md)
- [Escalation Procedures](./07-monitoring/escalation.md)
- [Metric Interpretation Guide](./07-monitoring/metric-interpretation.md)
- [Dashboard Configuration](./07-monitoring/dashboard-config.md)
- [Set Up New Alerts](./07-monitoring/alert-setup.md)

### 08 - Organization Management
- [Onboard New Tenant](./08-organization/tenant-onboarding.md)
- [Update License Limits](./08-organization/update-license.md)
- [Adjust Resource Quotas](./08-organization/adjust-quotas.md)
- [Suspend Organization](./08-organization/suspend-organization.md)
- [Delete Organization](./08-organization/delete-organization.md)
- [Migrate Organization Between Tiers](./08-organization/tier-migration.md)

### 09 - Infrastructure Provisioning
- [Terraform Deployment Recovery](./09-infrastructure/terraform-recovery.md)
- [Cloud Provider API Issues](./09-infrastructure/cloud-api-issues.md)
- [Networking Problems](./09-infrastructure/networking-issues.md)
- [SSH Key Rotation](./09-infrastructure/ssh-key-rotation.md)
- [Server Registration Failure](./09-infrastructure/server-registration-failure.md)

### 10 - Integration Failures
- [Payment Gateway Issues](./10-integrations/payment-gateway-issues.md)
- [DNS Propagation Delays](./10-integrations/dns-propagation.md)
- [Webhook Failures](./10-integrations/webhook-failures.md)
- [Email Delivery Problems](./10-integrations/email-delivery.md)
- [Domain Registrar Issues](./10-integrations/domain-registrar.md)

## Using These Runbooks

### For On-Call Engineers
1. **Alert Triggered**: Check [Alert Triage](./07-monitoring/alert-triage.md) for initial response steps
2. **Identify Scenario**: Match alert to runbook category
3. **Follow Procedure**: Execute runbook steps sequentially
4. **Document**: Log actions taken in operations log
5. **Post-Incident**: Update runbook with lessons learned

### For Scheduled Maintenance
1. **Review Plan**: Select appropriate runbooks for maintenance tasks
2. **Assess Impact**: Review "Impact Assessment" section
3. **Schedule Window**: Choose low-traffic period
4. **Execute**: Follow steps with validation at each stage
5. **Monitor**: Watch metrics for 1 hour post-maintenance

### For Training
1. **New Team Members**: Start with "Common Operations" runbooks
2. **Tabletop Exercises**: Use disaster recovery runbooks for drills
3. **Practice**: Run non-critical runbooks in staging environment
4. **Certification**: Complete runbook execution checklist

## Runbook Maintenance

### Update Schedule
- **Weekly**: Review runbooks used during incidents
- **Monthly**: DevOps team reviews most-used runbooks
- **Quarterly**: Complete audit of all runbooks for accuracy
- **Annually**: Major revision aligning with platform changes

### Contribution Process
1. Create branch: `runbooks/update-<runbook-name>`
2. Make changes following template structure
3. Test procedure in staging environment
4. Submit pull request with review checklist
5. Require approval from 2 team members
6. Merge and deploy to documentation portal

### Feedback
- **Slack Channel**: #ops-runbooks for discussions
- **GitHub Issues**: Report errors or suggest improvements
- **Post-Incident Reviews**: Identify runbook gaps
- **Surveys**: Quarterly feedback from on-call engineers

## Emergency Contacts

### Primary On-Call Rotation
- **PagerDuty**: https://coolify.pagerduty.com/schedules
- **Slack**: #incidents (for real-time coordination)

### Escalation Paths
- **L1**: On-Call Engineer (PagerDuty rotation)
- **L2**: DevOps Team Lead (@devops-lead)
- **L3**: Infrastructure Engineer (@infra-lead)
- **L4**: CTO (critical business impact only)

### External Vendors
- **AWS Support**: Enterprise Support (phone +1-800-AWS)
- **Database Vendor**: PostgreSQL Consulting (support@pgconsulting.com)
- **Monitoring Vendor**: Datadog Support (support@datadog.com)

## Compliance & Auditing

### SOC 2 Requirements
- All operational changes must be logged
- Runbooks reviewed quarterly by security team
- Access to production requires documented procedures
- Incident response procedures tested annually

### Audit Trail
- Operations logged in: `operation_logs` database table
- Command history: `/var/log/coolify/operations.log`
- Change management: GitHub pull requests for runbook updates
```

## Implementation Approach

### Step 1: Create Directory Structure
```bash
mkdir -p docs/operations/runbooks/{01-scaling,02-backup-restore,03-disaster-recovery,04-troubleshooting,05-security,06-deployment,07-monitoring,08-organization,09-infrastructure,10-integrations,templates}
```

### Step 2: Create Template and Index
1. Create `docs/operations/runbooks/templates/runbook-template.md` with standard structure
2. Create `docs/operations/runbooks/README.md` with runbook index
3. Commit to version control

### Step 3: Write Critical Runbooks (Priority 1)
**Week 1:**
- Database Backup & Restore
- Disaster Recovery - Complete System
- Security Incident Response
- Zero-Downtime Deployment

**Week 2:**
- Scale Queue Workers
- Scale Application Servers
- Database Migration
- Rollback Deployment

### Step 4: Write Common Operations Runbooks (Priority 2)
**Week 3:**
- Slow Database Queries
- High CPU/Memory Troubleshooting
- Queue Congestion
- Cache Issues

**Week 4:**
- Terraform Deployment Recovery
- Payment Gateway Issues
- DNS Propagation Delays
- Webhook Failures

### Step 5: Write Specialized Runbooks (Priority 3)
**Week 5:**
- Tenant Onboarding/Management
- License Updates
- Multi-Region Failover
- DDoS Response

**Week 6:**
- Monitoring Alert Setup
- Dashboard Configuration
- Canary Deployment
- Blue-Green Deployment

### Step 6: Create Automation Scripts
1. Create `scripts/operations/` directory
2. Write automation scripts referenced in runbooks:
   - `scale-workers.sh`
   - `backup-database.sh`
   - `restore-database.sh`
   - `validate-deployment.sh`
   - `health-check.sh`
3. Make scripts executable and add error handling

### Step 7: Deploy Documentation Portal
1. Set up MkDocs or similar documentation generator
2. Configure searchable index
3. Add PDF export capability for offline access
4. Deploy to internal wiki or documentation portal

### Step 8: Training and Validation
1. Schedule runbook training sessions with on-call team
2. Conduct tabletop exercises using disaster recovery runbooks
3. Practice non-critical runbooks in staging environment
4. Collect feedback and iterate

### Step 9: Integration with Operations
1. Link runbooks from monitoring alerts (alert message includes runbook URL)
2. Add runbook references to PagerDuty incident templates
3. Include runbook execution in post-incident review checklist
4. Track MTTR improvements after runbook implementation

### Step 10: Establish Maintenance Process
1. Create quarterly review schedule
2. Assign runbook owners for each document
3. Set up automated reminders for reviews
4. Create feedback mechanism (Slack channel, GitHub issues)

## Test Strategy

### Runbook Validation Checklist

**File:** `docs/operations/runbooks/VALIDATION_CHECKLIST.md`

```markdown
# Runbook Validation Checklist

Use this checklist when creating or updating runbooks to ensure quality and completeness.

## Template Compliance
- [ ] Follows standard template structure
- [ ] Contains all required sections (Overview, Prerequisites, Impact, Procedure, Validation, Rollback)
- [ ] Front matter includes: Last Updated, Owner, Severity, Estimated Time
- [ ] Markdown formatting valid (lint with markdownlint)

## Content Quality
- [ ] Overview explains purpose clearly
- [ ] "When to Use" scenarios are specific and actionable
- [ ] Prerequisites list all required access, tools, and information
- [ ] Impact assessment covers downtime, user impact, rollback capability
- [ ] Procedure steps are numbered and sequential
- [ ] Each step includes exact commands with expected output
- [ ] Validation checks provided for each step
- [ ] Troubleshooting section addresses common issues
- [ ] Rollback procedure complete and tested

## Technical Accuracy
- [ ] All commands tested in staging environment
- [ ] Expected outputs match actual outputs
- [ ] File paths and URLs are accurate
- [ ] Environment variables referenced correctly
- [ ] Tool versions specified where relevant

## Operational Excellence
- [ ] Estimated time realistic (tested by multiple engineers)
- [ ] Escalation contacts current and accurate
- [ ] Related runbooks cross-referenced
- [ ] Automation opportunities identified
- [ ] External documentation links valid

## Safety & Security
- [ ] Commands reviewed for destructive operations
- [ ] Backup steps included before destructive operations
- [ ] Credential handling follows security best practices
- [ ] Access requirements comply with least privilege principle
- [ ] Compliance requirements noted (SOC 2, GDPR, etc.)

## Usability
- [ ] Runbook readable without scrolling back-and-forth
- [ ] Commands can be copy-pasted without modification (except variables)
- [ ] Technical jargon explained or linked to glossary
- [ ] Screenshots/diagrams included where helpful
- [ ] Runbook readable by engineer unfamiliar with system

## Testing
- [ ] Runbook executed end-to-end in staging
- [ ] Rollback procedure validated
- [ ] Timing accurate (steps complete within estimated time)
- [ ] No missing prerequisites discovered during execution
- [ ] Post-execution validation confirms success

## Documentation
- [ ] Change log updated with creation/modification details
- [ ] Runbook indexed in README.md
- [ ] Related runbooks updated with cross-references
- [ ] Operations team notified of new/updated runbook

## Sign-Off
- [ ] Reviewed by runbook owner
- [ ] Reviewed by operations team lead
- [ ] Approved by at least 2 engineers
- [ ] Deployed to documentation portal
```

### Tabletop Exercise Template

**File:** `docs/operations/runbooks/TABLETOP_EXERCISE.md`

```markdown
# Runbook Tabletop Exercise Template

## Exercise Information
- **Date**: [Date]
- **Facilitator**: [Name]
- **Participants**: [Names]
- **Runbook Being Tested**: [Runbook Title]
- **Scenario**: [Incident scenario description]

## Objectives
1. Validate runbook completeness and accuracy
2. Identify gaps in procedure or documentation
3. Practice incident response as a team
4. Measure time-to-resolution

## Scenario Setup
[Describe the hypothetical incident that triggers use of this runbook]

**Example:**
"At 2:00 AM on a Saturday, PagerDuty alerts that the deployments queue has 5,000 pending jobs and deployment times have increased from 5 minutes to 45 minutes. The on-call engineer needs to scale queue workers to reduce queue backlog."

## Exercise Execution

### Phase 1: Initial Response (5 minutes)
- On-call engineer acknowledges alert
- Engineer identifies appropriate runbook
- Reviews prerequisites and impact assessment

**Questions:**
- What information does the engineer need before starting?
- Are all prerequisites available/accessible?
- Is the impact assessment accurate?

### Phase 2: Procedure Execution (Walkthrough)
- Engineer walks through each step verbally
- Team validates commands and expected outputs
- Identify any missing steps or unclear instructions

**Capture:**
- Steps that are unclear or confusing
- Missing validation checks
- Commands that need correction
- Missing troubleshooting scenarios

### Phase 3: Validation & Rollback (5 minutes)
- Review validation steps
- Discuss rollback procedure
- Identify rollback gaps

**Questions:**
- Are validation steps sufficient to confirm success?
- Is rollback procedure complete?
- What happens if rollback also fails?

### Phase 4: Debrief (10 minutes)
- What worked well?
- What was missing or incorrect?
- How could this runbook be improved?
- What automation opportunities exist?

## Findings

### Gaps Identified
| Issue | Severity | Action Item | Owner | Due Date |
|-------|----------|-------------|-------|----------|
|       |          |             |       |          |

### Positive Observations
| Item | Notes |
|------|-------|
|      |       |

### Improvements
| Improvement | Priority | Assigned To | Status |
|-------------|----------|-------------|--------|
|             |          |             |        |

## Follow-Up Actions
- [ ] Update runbook with corrections
- [ ] Add missing steps or validation checks
- [ ] Update troubleshooting section
- [ ] Re-test in staging environment
- [ ] Schedule re-validation exercise

## Sign-Off
- **Exercise Completed**: [Date]
- **Runbook Updated**: [Date]
- **Approved By**: [Name]
```

## Definition of Done

- [ ] Runbook directory structure created in `docs/operations/runbooks/`
- [ ] Standard runbook template created and documented
- [ ] Runbook index (README.md) created with all categories
- [ ] 10+ scaling runbooks written (app servers, workers, databases, Redis, WebSockets)
- [ ] 6+ backup/restore runbooks written (database, config, Terraform, application data)
- [ ] 4+ disaster recovery runbooks written (complete system, database failover, multi-region, datacenter evacuation)
- [ ] 8+ troubleshooting runbooks written (slow queries, high CPU/memory, queues, cache, errors)
- [ ] 6+ security runbooks written (incident response, credential rotation, data leaks, API abuse, DDoS)
- [ ] 6+ deployment runbooks written (zero-downtime, rollback, migrations, feature flags, blue-green, canary)
- [ ] 5+ monitoring runbooks written (alert triage, escalation, metrics, dashboards, alert setup)
- [ ] 6+ organization management runbooks written (onboarding, licenses, quotas, suspension, deletion, tier migration)
- [ ] 5+ infrastructure runbooks written (Terraform recovery, cloud APIs, networking, SSH keys, server registration)
- [ ] 5+ integration runbooks written (payment gateways, DNS, webhooks, email, domain registrars)
- [ ] All runbooks follow consistent template structure
- [ ] Each runbook includes exact commands with expected outputs
- [ ] Each runbook includes rollback procedures
- [ ] Each runbook includes troubleshooting section
- [ ] Each runbook tested in staging environment
- [ ] Automation scripts created for common operations
- [ ] Runbook validation checklist created
- [ ] Tabletop exercise template created
- [ ] At least 3 tabletop exercises conducted with on-call team
- [ ] Documentation portal deployed with searchable index
- [ ] Runbooks linked from monitoring alerts
- [ ] Runbook references added to PagerDuty templates
- [ ] On-call team trained on critical runbooks
- [ ] Quarterly review process established
- [ ] Feedback mechanism created (Slack channel or GitHub issues)
- [ ] Runbook effectiveness measured via MTTR tracking
- [ ] Operations team signs off on runbook completeness
- [ ] Security team reviews compliance aspects
- [ ] CTO approves runbook library for production use

## Related Tasks

- **Depends on:** All previous tasks (runbooks reference enterprise features)
- **Integrates with:** Task 89 (CI/CD pipeline procedures)
- **Integrates with:** Task 91 (Monitoring dashboards and alerting)
- **Integrates with:** Task 82-86 (Feature documentation provides context)
- **Supports:** All operational aspects of Coolify Enterprise platform
